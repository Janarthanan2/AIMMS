{
  "best_global_step": 264,
  "best_metric": 0.0566464364528656,
  "best_model_checkpoint": "./results\\checkpoint-264",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 264,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07575757575757576,
      "grad_norm": 2.422645330429077,
      "learning_rate": 9e-07,
      "loss": 2.399,
      "step": 10
    },
    {
      "epoch": 0.15151515151515152,
      "grad_norm": 2.467054843902588,
      "learning_rate": 1.9e-06,
      "loss": 2.399,
      "step": 20
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 1.814244031906128,
      "learning_rate": 2.9e-06,
      "loss": 2.3995,
      "step": 30
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 2.1483314037323,
      "learning_rate": 3.9e-06,
      "loss": 2.3961,
      "step": 40
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 2.5124318599700928,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 2.3698,
      "step": 50
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 2.4453933238983154,
      "learning_rate": 5.9e-06,
      "loss": 2.3677,
      "step": 60
    },
    {
      "epoch": 0.5303030303030303,
      "grad_norm": 2.9955546855926514,
      "learning_rate": 6.900000000000001e-06,
      "loss": 2.3272,
      "step": 70
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 3.404359817504883,
      "learning_rate": 7.9e-06,
      "loss": 2.2792,
      "step": 80
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 3.7190539836883545,
      "learning_rate": 8.9e-06,
      "loss": 2.1754,
      "step": 90
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 3.9751367568969727,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.0933,
      "step": 100
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 3.7329065799713135,
      "learning_rate": 1.09e-05,
      "loss": 1.987,
      "step": 110
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 3.6613800525665283,
      "learning_rate": 1.19e-05,
      "loss": 1.8563,
      "step": 120
    },
    {
      "epoch": 0.9848484848484849,
      "grad_norm": 3.4908061027526855,
      "learning_rate": 1.29e-05,
      "loss": 1.6744,
      "step": 130
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.512425184249878,
      "eval_runtime": 1.2007,
      "eval_samples_per_second": 438.08,
      "eval_steps_per_second": 7.496,
      "step": 132
    },
    {
      "epoch": 1.0606060606060606,
      "grad_norm": 3.7612967491149902,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 1.4926,
      "step": 140
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 3.972611665725708,
      "learning_rate": 1.49e-05,
      "loss": 1.3415,
      "step": 150
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 3.73840594291687,
      "learning_rate": 1.59e-05,
      "loss": 1.1123,
      "step": 160
    },
    {
      "epoch": 1.2878787878787878,
      "grad_norm": 3.7567176818847656,
      "learning_rate": 1.69e-05,
      "loss": 1.109,
      "step": 170
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 3.2809219360351562,
      "learning_rate": 1.79e-05,
      "loss": 0.8692,
      "step": 180
    },
    {
      "epoch": 1.4393939393939394,
      "grad_norm": 3.3384366035461426,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.6961,
      "step": 190
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 3.231308937072754,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.5976,
      "step": 200
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 2.878763437271118,
      "learning_rate": 2.09e-05,
      "loss": 0.4652,
      "step": 210
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 2.114386796951294,
      "learning_rate": 2.19e-05,
      "loss": 0.3677,
      "step": 220
    },
    {
      "epoch": 1.7424242424242424,
      "grad_norm": 3.9730112552642822,
      "learning_rate": 2.29e-05,
      "loss": 0.2559,
      "step": 230
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 1.6312488317489624,
      "learning_rate": 2.39e-05,
      "loss": 0.1783,
      "step": 240
    },
    {
      "epoch": 1.893939393939394,
      "grad_norm": 0.934374213218689,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.143,
      "step": 250
    },
    {
      "epoch": 1.9696969696969697,
      "grad_norm": 0.5758762955665588,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.1118,
      "step": 260
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0566464364528656,
      "eval_runtime": 1.2463,
      "eval_samples_per_second": 422.044,
      "eval_steps_per_second": 7.221,
      "step": 264
    }
  ],
  "logging_steps": 10,
  "max_steps": 396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 14135401444164.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
