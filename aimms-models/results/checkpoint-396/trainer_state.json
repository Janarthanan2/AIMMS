{
  "best_global_step": 396,
  "best_metric": 0.0077416542917490005,
  "best_model_checkpoint": "./results\\checkpoint-396",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 396,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07575757575757576,
      "grad_norm": 2.422645330429077,
      "learning_rate": 9e-07,
      "loss": 2.399,
      "step": 10
    },
    {
      "epoch": 0.15151515151515152,
      "grad_norm": 2.467054843902588,
      "learning_rate": 1.9e-06,
      "loss": 2.399,
      "step": 20
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 1.814244031906128,
      "learning_rate": 2.9e-06,
      "loss": 2.3995,
      "step": 30
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 2.1483314037323,
      "learning_rate": 3.9e-06,
      "loss": 2.3961,
      "step": 40
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 2.5124318599700928,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 2.3698,
      "step": 50
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 2.4453933238983154,
      "learning_rate": 5.9e-06,
      "loss": 2.3677,
      "step": 60
    },
    {
      "epoch": 0.5303030303030303,
      "grad_norm": 2.9955546855926514,
      "learning_rate": 6.900000000000001e-06,
      "loss": 2.3272,
      "step": 70
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 3.404359817504883,
      "learning_rate": 7.9e-06,
      "loss": 2.2792,
      "step": 80
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 3.7190539836883545,
      "learning_rate": 8.9e-06,
      "loss": 2.1754,
      "step": 90
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 3.9751367568969727,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.0933,
      "step": 100
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 3.7329065799713135,
      "learning_rate": 1.09e-05,
      "loss": 1.987,
      "step": 110
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 3.6613800525665283,
      "learning_rate": 1.19e-05,
      "loss": 1.8563,
      "step": 120
    },
    {
      "epoch": 0.9848484848484849,
      "grad_norm": 3.4908061027526855,
      "learning_rate": 1.29e-05,
      "loss": 1.6744,
      "step": 130
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.512425184249878,
      "eval_runtime": 1.2007,
      "eval_samples_per_second": 438.08,
      "eval_steps_per_second": 7.496,
      "step": 132
    },
    {
      "epoch": 1.0606060606060606,
      "grad_norm": 3.7612967491149902,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 1.4926,
      "step": 140
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 3.972611665725708,
      "learning_rate": 1.49e-05,
      "loss": 1.3415,
      "step": 150
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 3.73840594291687,
      "learning_rate": 1.59e-05,
      "loss": 1.1123,
      "step": 160
    },
    {
      "epoch": 1.2878787878787878,
      "grad_norm": 3.7567176818847656,
      "learning_rate": 1.69e-05,
      "loss": 1.109,
      "step": 170
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 3.2809219360351562,
      "learning_rate": 1.79e-05,
      "loss": 0.8692,
      "step": 180
    },
    {
      "epoch": 1.4393939393939394,
      "grad_norm": 3.3384366035461426,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.6961,
      "step": 190
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 3.231308937072754,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.5976,
      "step": 200
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 2.878763437271118,
      "learning_rate": 2.09e-05,
      "loss": 0.4652,
      "step": 210
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 2.114386796951294,
      "learning_rate": 2.19e-05,
      "loss": 0.3677,
      "step": 220
    },
    {
      "epoch": 1.7424242424242424,
      "grad_norm": 3.9730112552642822,
      "learning_rate": 2.29e-05,
      "loss": 0.2559,
      "step": 230
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 1.6312488317489624,
      "learning_rate": 2.39e-05,
      "loss": 0.1783,
      "step": 240
    },
    {
      "epoch": 1.893939393939394,
      "grad_norm": 0.934374213218689,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.143,
      "step": 250
    },
    {
      "epoch": 1.9696969696969697,
      "grad_norm": 0.5758762955665588,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.1118,
      "step": 260
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0566464364528656,
      "eval_runtime": 1.2463,
      "eval_samples_per_second": 422.044,
      "eval_steps_per_second": 7.221,
      "step": 264
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 0.469625860452652,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.08,
      "step": 270
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 0.2836107015609741,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0523,
      "step": 280
    },
    {
      "epoch": 2.196969696969697,
      "grad_norm": 0.2775075435638428,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0476,
      "step": 290
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.24186314642429352,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0363,
      "step": 300
    },
    {
      "epoch": 2.3484848484848486,
      "grad_norm": 0.205783873796463,
      "learning_rate": 3.09e-05,
      "loss": 0.0318,
      "step": 310
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.17584726214408875,
      "learning_rate": 3.19e-05,
      "loss": 0.0256,
      "step": 320
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.161577507853508,
      "learning_rate": 3.29e-05,
      "loss": 0.023,
      "step": 330
    },
    {
      "epoch": 2.5757575757575757,
      "grad_norm": 0.16219758987426758,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0223,
      "step": 340
    },
    {
      "epoch": 2.6515151515151514,
      "grad_norm": 0.1273876428604126,
      "learning_rate": 3.49e-05,
      "loss": 0.0174,
      "step": 350
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.11938855797052383,
      "learning_rate": 3.59e-05,
      "loss": 0.0157,
      "step": 360
    },
    {
      "epoch": 2.8030303030303028,
      "grad_norm": 0.12369807064533234,
      "learning_rate": 3.69e-05,
      "loss": 0.0147,
      "step": 370
    },
    {
      "epoch": 2.878787878787879,
      "grad_norm": 0.09800539165735245,
      "learning_rate": 3.79e-05,
      "loss": 0.0135,
      "step": 380
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 0.10112433135509491,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0126,
      "step": 390
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0077416542917490005,
      "eval_runtime": 1.2204,
      "eval_samples_per_second": 431.006,
      "eval_steps_per_second": 7.375,
      "step": 396
    }
  ],
  "logging_steps": 10,
  "max_steps": 396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 21203102166246.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
